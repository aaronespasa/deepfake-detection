{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: CUDA:0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Running on device: {DEVICE.upper()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTCNN & Classfier models loaded\n"
     ]
    }
   ],
   "source": [
    "mtcnn = MTCNN(\n",
    "    select_largest=False,\n",
    "    post_process=False,\n",
    "    device=DEVICE\n",
    ").to(DEVICE).eval()\n",
    "\n",
    "model = InceptionResnetV1(\n",
    "    pretrained=\"vggface2\",\n",
    "    classify=True,\n",
    "    num_classes=1,\n",
    "    device=DEVICE\n",
    ")\n",
    "model.load_state_dict(torch.load('./models/resnetinceptionv1_final.pth'))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "print(\"MTCNN & Classfier models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES_FOLDER = 'examples'\n",
    "examples_names = os.listdir(EXAMPLES_FOLDER)\n",
    "examples = []\n",
    "for example_name in examples_names:\n",
    "    example_path = os.path.join(EXAMPLES_FOLDER, example_name)\n",
    "    label = example_name.split('_')[0]\n",
    "    example = {\n",
    "        'path': example_path,\n",
    "        'label': label\n",
    "    }\n",
    "    examples.append(example)\n",
    "# np.random.shuffle(examples) # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_image:Image.Image):\n",
    "    \"\"\"Predict the label of the input_image\"\"\"\n",
    "    face = mtcnn(input_image)\n",
    "    if face is None:\n",
    "        raise Exception('No face detected')\n",
    "    face = face.unsqueeze(0) # add the batch dimension\n",
    "    face = F.interpolate(face, size=(256, 256), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    # convert the face into a numpy array to be able to plot it\n",
    "    face_image_to_plot = face.squeeze(0).permute(1, 2, 0).cpu().detach().int().numpy()\n",
    "\n",
    "    face = face.to(DEVICE)\n",
    "    face = face.to(torch.float32)\n",
    "    face = face / 255.0\n",
    "    with torch.no_grad():\n",
    "        output = torch.sigmoid(model(face).squeeze(0))\n",
    "        prediction = \"real\" if output.item() < 0.5 else \"fake\"\n",
    "        \n",
    "        real_prediction = 1 - output.item()\n",
    "        fake_prediction = output.item()\n",
    "        \n",
    "        confidences = {\n",
    "            'real': real_prediction,\n",
    "            'fake': fake_prediction\n",
    "        }\n",
    "    return confidences, face_image_to_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: fake\n",
      "Predicted label: real\n",
      "\n",
      "True label: fake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espasa/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: real\n",
      "\n",
      "True label: fake\n",
      "Predicted label: real\n",
      "\n",
      "True label: fake\n",
      "Predicted label: real\n",
      "\n",
      "True label: fake\n",
      "Predicted label: real\n",
      "\n",
      "True label: fake\n",
      "Predicted label: real\n",
      "\n",
      "True label: fake\n",
      "Predicted label: real\n",
      "\n",
      "True label: fake\n",
      "Predicted label: real\n",
      "\n",
      "True label: fake\n",
      "Predicted label: real\n",
      "\n",
      "True label: fake\n",
      "Predicted label: real\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    example = examples[8]\n",
    "    example_img = example['path']\n",
    "    example_label = example['label']\n",
    "\n",
    "    print(f\"True label: {example_label}\")\n",
    "\n",
    "    example_img = Image.open(example_img)\n",
    "    confidences, _ = predict(example_img)\n",
    "    if confidences['real'] > 0.5:\n",
    "        print(\"Predicted label: real\")\n",
    "    else:\n",
    "        print(\"Predicted label: fake\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espasa/anaconda3/envs/pytorch/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "/home/espasa/anaconda3/envs/pytorch/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7874/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7874/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa9b420deb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espasa/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    }
   ],
   "source": [
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.inputs.Image(label=\"Input Image\", type=\"pil\"),\n",
    "    outputs=[\n",
    "        gr.outputs.Label(label=\"Class\"),\n",
    "        gr.outputs.Image(label=\"Face\")\n",
    "    ],\n",
    "    examples=[examples[i][\"path\"] for i in range(8)] # fake examples\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1df8ca6470716aef7885428a3615d7cfcd80d77664baa0ca314c31299e302aab"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
